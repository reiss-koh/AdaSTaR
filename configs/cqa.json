{
    "epochs": 1,
    "grad_accumulation": 1,
    "gen_length": 159,
    "batch_size": 2,
    "test_batch_size": 32,
    "lr": 1e-05,
    "weight_decay": 0.01,
    "warm_up_steps": 100,
    "model_dir": "checkpoints/",
    "log_divisor": 100,
    "save_divisor": 5,
    "exp_name": "testrun",
    "optimizer": "Adam",
    "scheduler": "linear",
    "precision": "bf16",
    "model_name": "meta-llama/Llama-3.2-3B",
    "max_length": 256,
    "n_shot": 7,
    "self_consistency": 0,
    "delete_model_after_loading": true,
    "accumulate": false,
    "task": "cqa",
    "inference_temp": 1.0,
    "no_hint": false,
    "base_model_path" : null
}
